import os
import requests
import numpy as np
import textwrap
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st


class VectorStore:
    def __init__(self, api_key=None):
        self.api_key = api_key or os.getenv("UPSTAGE_API_KEY")
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        self.vectors = []  # (embedding, text, metadata)

    def get_embedding(self, text: str):
        url = "https://api.upstage.ai/v1/embeddings"
        model = "embedding-query"

        chunks = textwrap.wrap(text, 1000)
        embeddings = []

        st.write(f"ğŸ“ ì´ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í•  (ê° ìµœëŒ€ 1000ì)")

        for i, chunk in enumerate(chunks, 1):
            payload = {"input": chunk, "model": model}
            try:
                res = requests.post(url, headers=self.headers, json=payload)
                res.raise_for_status()
                emb = res.json()["data"][0]["embedding"]
                embeddings.append(emb)
                st.write(f"âœ… Chunk {i} ì„ë² ë”© ì™„ë£Œ (ë²¡í„° ê¸¸ì´: {len(emb)})")
            except Exception as e:
                st.error(f"âŒ Chunk {i} ì„ë² ë”© ì‹¤íŒ¨: {e}")
                continue

        if not embeddings:
            raise RuntimeError("âŒ ëª¨ë“  chunk ì„ë² ë”© ì‹¤íŒ¨. ë²¡í„° ìƒì„± ë¶ˆê°€")

        avg_embedding = np.mean(np.array(embeddings), axis=0)
        return avg_embedding.tolist()

    def add_document(self, text, metadata=None):
        try:
            if not text.strip():
                st.warning("âš ï¸ ë¹ˆ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë²¡í„°í™” ê±´ë„ˆëœ€")
                return
            st.write(f"ğŸ“ ë¬¸ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
            emb = self.get_embedding(text)
            self.vectors.append((np.array(emb), text, metadata or {}))
            st.success("ğŸ§  ë¬¸ì„œ ë²¡í„° ì €ì¥ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"âŒ ë¬¸ì„œ ë²¡í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    def search(self, query: str, top_k: int = 5):
        try:
            query_emb = np.array(self.get_embedding(query)).reshape(1, -1)
            if not self.vectors:
                st.warning("âš ï¸ ì €ì¥ëœ ë¬¸ì„œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            doc_embeddings = np.array([vec[0] for vec in self.vectors])
            sims = cosine_similarity(query_emb, doc_embeddings)[0]
            top_indices = sims.argsort()[::-1][:top_k]

            results = []
            for idx in top_indices:
                emb, text, meta = self.vectors[idx]
                results.append({"text": text, "metadata": meta, "score": float(sims[idx])})

            return results
        except Exception as e:
            st.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
